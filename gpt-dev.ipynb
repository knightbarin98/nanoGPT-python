{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6488c8-9a94-4aad-811f-ed8c7cfe3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('harrypotter.txt', 'r', encoding='utf-8') as f:\n",
    "    hp = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b40178c-ae1d-43a3-a69d-58b2ca65079f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters 6435489\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters\", len(hp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d248f2d4-d003-409f-b091-9da9b0a3a71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter : THE BOY WHO LIVED .\n",
      "Mr and Mrs Dursley , of number four , Privet Drive , were proud to say that they were perfectly normal , thank you very much .\n",
      "They were the last people you'd expect to be involved in anything strange or mysterious , because they just didn't hold with such nonsense .\n",
      "Mr Dursley was the director of a firm called Grunnings , which made drills .\n",
      "He was a big , beefy man with hardly any neck , although he did have a very large mustache .\n",
      "Mrs Dursley was thin and blonde and had nearly twice the usual amount of neck , which came in very useful as she spent so much of her time craning over garden fences , spying on the neighbors .\n",
      "The Dursley s had a small son called Dudley and in their opinion there was no finer boy anywhere .\n",
      "The Dursleys had everything they wanted , but they also had a secret , and their greatest fear was that somebody would discover it .\n",
      "They didn't think they could bear it if anyone found out about the Potters .\n",
      "Mrs Potter was Mrs Dursley's \n"
     ]
    }
   ],
   "source": [
    "print(hp[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac41beb-6560-4e86-8300-6cb3278f9a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"&'(),.0123456789:?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(hp)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d51356a-77b5-4240-ac22-d52a41df531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 69, 48, 61, 1, 59, 62, 69, 52, 66, 1, 29, 48, 65, 65, 72, 1, 37, 62, 67, 67, 52, 65]\n",
      "but likes also LOTR\n"
     ]
    }
   ],
   "source": [
    "#tokenize the input text\n",
    "#tokenize = convert raw text strings to a sequence\n",
    "#create mapping from characters to integers\n",
    "string_to_index = {ch:i for i, ch in enumerate(chars)}\n",
    "index_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_index[ch] for ch in s] #encode: take a string, output a list of integers of that string\n",
    "decode = lambda l: ''.join([index_to_string[i] for i in l]) #decoder:  take a list of integers (encoded integers), output string\n",
    "\n",
    "print(encode(\"Ivan loves Harry Potter\"))\n",
    "print(decode(encode(\"but likes also LOTR\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b5a9f7-2b32-480e-baf0-97311605b5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6435489]) torch.int64\n",
      "tensor([24, 55, 48, 63, 67, 52, 65,  1, 20,  1, 41, 29, 26,  1, 23, 36, 46,  1,\n",
      "        44, 29, 36,  1, 33, 30, 43, 26, 25,  1,  9,  0, 34, 65,  1, 48, 61, 51,\n",
      "         1, 34, 65, 66,  1, 25, 68, 65, 66, 59, 52, 72,  1,  8,  1, 62, 53,  1,\n",
      "        61, 68, 60, 49, 52, 65,  1, 53, 62, 68, 65,  1,  8,  1, 37, 65, 56, 69,\n",
      "        52, 67,  1, 25, 65, 56, 69, 52,  1,  8,  1, 70, 52, 65, 52,  1, 63, 65,\n",
      "        62, 68, 51,  1, 67, 62,  1, 66, 48, 72,  1, 67, 55, 48, 67,  1, 67, 55,\n",
      "        52, 72,  1, 70, 52, 65, 52,  1, 63, 52, 65, 53, 52, 50, 67, 59, 72,  1,\n",
      "        61, 62, 65, 60, 48, 59,  1,  8,  1, 67, 55, 48, 61, 58,  1, 72, 62, 68,\n",
      "         1, 69, 52, 65, 72,  1, 60, 68, 50, 55,  1,  9,  0, 41, 55, 52, 72,  1,\n",
      "        70, 52, 65, 52,  1, 67, 55, 52,  1, 59, 48, 66, 67,  1, 63, 52, 62, 63,\n",
      "        59, 52,  1, 72, 62, 68,  5, 51,  1, 52, 71, 63, 52, 50, 67,  1, 67, 62,\n",
      "         1, 49, 52,  1, 56, 61, 69, 62, 59, 69, 52, 51,  1, 56, 61,  1, 48, 61,\n",
      "        72, 67, 55, 56, 61, 54,  1, 66, 67, 65, 48, 61, 54, 52,  1, 62, 65,  1,\n",
      "        60, 72, 66, 67, 52, 65, 56, 62, 68, 66,  1,  8,  1, 49, 52, 50, 48, 68,\n",
      "        66, 52,  1, 67, 55, 52, 72,  1, 57, 68, 66, 67,  1, 51, 56, 51, 61,  5,\n",
      "        67,  1, 55, 62, 59, 51,  1, 70, 56, 67, 55,  1, 66, 68, 50, 55,  1, 61,\n",
      "        62, 61, 66, 52, 61, 66, 52,  1,  9,  0, 34, 65,  1, 25, 68, 65, 66, 59,\n",
      "        52, 72,  1, 70, 48, 66,  1, 67, 55, 52,  1, 51, 56, 65, 52, 50, 67, 62,\n",
      "        65,  1, 62, 53,  1, 48,  1, 53, 56, 65, 60,  1, 50, 48, 59, 59, 52, 51,\n",
      "         1, 28, 65, 68, 61, 61, 56, 61, 54, 66,  1,  8,  1, 70, 55, 56, 50, 55,\n",
      "         1, 60, 48, 51, 52,  1, 51, 65, 56, 59, 59, 66,  1,  9,  0, 29, 52,  1,\n",
      "        70, 48, 66,  1, 48,  1, 49, 56, 54,  1,  8,  1, 49, 52, 52, 53, 72,  1,\n",
      "        60, 48, 61,  1, 70, 56, 67, 55,  1, 55, 48, 65, 51, 59, 72,  1, 48, 61,\n",
      "        72,  1, 61, 52, 50, 58,  1,  8,  1, 48, 59, 67, 55, 62, 68, 54, 55,  1,\n",
      "        55, 52,  1, 51, 56, 51,  1, 55, 48, 69, 52,  1, 48,  1, 69, 52, 65, 72,\n",
      "         1, 59, 48, 65, 54, 52,  1, 60, 68, 66, 67, 48, 50, 55, 52,  1,  9,  0,\n",
      "        34, 65, 66,  1, 25, 68, 65, 66, 59, 52, 72,  1, 70, 48, 66,  1, 67, 55,\n",
      "        56, 61,  1, 48, 61, 51,  1, 49, 59, 62, 61, 51, 52,  1, 48, 61, 51,  1,\n",
      "        55, 48, 51,  1, 61, 52, 48, 65, 59, 72,  1, 67, 70, 56, 50, 52,  1, 67,\n",
      "        55, 52,  1, 68, 66, 68, 48, 59,  1, 48, 60, 62, 68, 61, 67,  1, 62, 53,\n",
      "         1, 61, 52, 50, 58,  1,  8,  1, 70, 55, 56, 50, 55,  1, 50, 48, 60, 52,\n",
      "         1, 56, 61,  1, 69, 52, 65, 72,  1, 68, 66, 52, 53, 68, 59,  1, 48, 66,\n",
      "         1, 66, 55, 52,  1, 66, 63, 52, 61, 67,  1, 66, 62,  1, 60, 68, 50, 55,\n",
      "         1, 62, 53,  1, 55, 52, 65,  1, 67, 56, 60, 52,  1, 50, 65, 48, 61, 56,\n",
      "        61, 54,  1, 62, 69, 52, 65,  1, 54, 48, 65, 51, 52, 61,  1, 53, 52, 61,\n",
      "        50, 52, 66,  1,  8,  1, 66, 63, 72, 56, 61, 54,  1, 62, 61,  1, 67, 55,\n",
      "        52,  1, 61, 52, 56, 54, 55, 49, 62, 65, 66,  1,  9,  0, 41, 55, 52,  1,\n",
      "        25, 68, 65, 66, 59, 52, 72,  1, 66,  1, 55, 48, 51,  1, 48,  1, 66, 60,\n",
      "        48, 59, 59,  1, 66, 62, 61,  1, 50, 48, 59, 59, 52, 51,  1, 25, 68, 51,\n",
      "        59, 52, 72,  1, 48, 61, 51,  1, 56, 61,  1, 67, 55, 52, 56, 65,  1, 62,\n",
      "        63, 56, 61, 56, 62, 61,  1, 67, 55, 52, 65, 52,  1, 70, 48, 66,  1, 61,\n",
      "        62,  1, 53, 56, 61, 52, 65,  1, 49, 62, 72,  1, 48, 61, 72, 70, 55, 52,\n",
      "        65, 52,  1,  9,  0, 41, 55, 52,  1, 25, 68, 65, 66, 59, 52, 72, 66,  1,\n",
      "        55, 48, 51,  1, 52, 69, 52, 65, 72, 67, 55, 56, 61, 54,  1, 67, 55, 52,\n",
      "        72,  1, 70, 48, 61, 67, 52, 51,  1,  8,  1, 49, 68, 67,  1, 67, 55, 52,\n",
      "        72,  1, 48, 59, 66, 62,  1, 55, 48, 51,  1, 48,  1, 66, 52, 50, 65, 52,\n",
      "        67,  1,  8,  1, 48, 61, 51,  1, 67, 55, 52, 56, 65,  1, 54, 65, 52, 48,\n",
      "        67, 52, 66, 67,  1, 53, 52, 48, 65,  1, 70, 48, 66,  1, 67, 55, 48, 67,\n",
      "         1, 66, 62, 60, 52, 49, 62, 51, 72,  1, 70, 62, 68, 59, 51,  1, 51, 56,\n",
      "        66, 50, 62, 69, 52, 65,  1, 56, 67,  1,  9,  0, 41, 55, 52, 72,  1, 51,\n",
      "        56, 51, 61,  5, 67,  1, 67, 55, 56, 61, 58,  1, 67, 55, 52, 72,  1, 50,\n",
      "        62, 68, 59, 51,  1, 49, 52, 48, 65,  1, 56, 67,  1, 56, 53,  1, 48, 61,\n",
      "        72, 62, 61, 52,  1, 53, 62, 68, 61, 51,  1, 62, 68, 67,  1, 48, 49, 62,\n",
      "        68, 67,  1, 67, 55, 52,  1, 37, 62, 67, 67, 52, 65, 66,  1,  9,  0, 34,\n",
      "        65, 66,  1, 37, 62, 67, 67, 52, 65,  1, 70, 48, 66,  1, 34, 65, 66,  1,\n",
      "        25, 68, 65, 66, 59, 52, 72,  5, 66,  1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(hp), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c97bf0-d176-49dc-b2ef-e800a82a534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's now split up the data into train and validation sets\n",
    "#will help us to understand how much our model is overfitting\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643717c4-9209-4b95-b05d-5b50780ea23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24, 55, 48, 63, 67, 52, 65,  1, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chapter :'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "print(train_data[:block_size+1])\n",
    "decode(train_data[:block_size+1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c953c63f-8128-4b3f-9d72-453e1c5716ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24, 55, 48, 63, 67, 52, 65,  1])\n",
      "tensor([55, 48, 63, 67, 52, 65,  1, 20])\n",
      "when input is tensor([24]) the target is: 55\n",
      "when input is tensor([24, 55]) the target is: 48\n",
      "when input is tensor([24, 55, 48]) the target is: 63\n",
      "when input is tensor([24, 55, 48, 63]) the target is: 67\n",
      "when input is tensor([24, 55, 48, 63, 67]) the target is: 52\n",
      "when input is tensor([24, 55, 48, 63, 67, 52]) the target is: 65\n",
      "when input is tensor([24, 55, 48, 63, 67, 52, 65]) the target is: 1\n",
      "when input is tensor([24, 55, 48, 63, 67, 52, 65,  1]) the target is: 20\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "print(x)\n",
    "y = train_data[1:block_size+1]\n",
    "print(y)\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f002717-2e80-447e-82ca-9e3713b3ae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[60, 60, 52, 51, 56, 48, 67, 52],\n",
      "        [ 8,  1, 67, 55, 48, 61, 58,  1],\n",
      "        [52, 63, 52, 65,  1, 56, 61, 67],\n",
      "        [62, 59, 51,  1, 70, 56, 73, 48]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[60, 52, 51, 56, 48, 67, 52, 59],\n",
      "        [ 1, 67, 55, 48, 61, 58,  1, 72],\n",
      "        [63, 52, 65,  1, 56, 61, 67, 62],\n",
      "        [59, 51,  1, 70, 56, 73, 48, 65]])\n",
      "when input is [60] the target is: 60\n",
      "m ----> m\n",
      "when input is [60, 60] the target is: 52\n",
      "mm ----> e\n",
      "when input is [60, 60, 52] the target is: 51\n",
      "mme ----> d\n",
      "when input is [60, 60, 52, 51] the target is: 56\n",
      "mmed ----> i\n",
      "when input is [60, 60, 52, 51, 56] the target is: 48\n",
      "mmedi ----> a\n",
      "when input is [60, 60, 52, 51, 56, 48] the target is: 67\n",
      "mmedia ----> t\n",
      "when input is [60, 60, 52, 51, 56, 48, 67] the target is: 52\n",
      "mmediat ----> e\n",
      "when input is [60, 60, 52, 51, 56, 48, 67, 52] the target is: 59\n",
      "mmediate ----> l\n",
      "when input is [8] the target is: 1\n",
      ", ---->  \n",
      "when input is [8, 1] the target is: 67\n",
      ",  ----> t\n",
      "when input is [8, 1, 67] the target is: 55\n",
      ", t ----> h\n",
      "when input is [8, 1, 67, 55] the target is: 48\n",
      ", th ----> a\n",
      "when input is [8, 1, 67, 55, 48] the target is: 61\n",
      ", tha ----> n\n",
      "when input is [8, 1, 67, 55, 48, 61] the target is: 58\n",
      ", than ----> k\n",
      "when input is [8, 1, 67, 55, 48, 61, 58] the target is: 1\n",
      ", thank ---->  \n",
      "when input is [8, 1, 67, 55, 48, 61, 58, 1] the target is: 72\n",
      ", thank  ----> y\n",
      "when input is [52] the target is: 63\n",
      "e ----> p\n",
      "when input is [52, 63] the target is: 52\n",
      "ep ----> e\n",
      "when input is [52, 63, 52] the target is: 65\n",
      "epe ----> r\n",
      "when input is [52, 63, 52, 65] the target is: 1\n",
      "eper ---->  \n",
      "when input is [52, 63, 52, 65, 1] the target is: 56\n",
      "eper  ----> i\n",
      "when input is [52, 63, 52, 65, 1, 56] the target is: 61\n",
      "eper i ----> n\n",
      "when input is [52, 63, 52, 65, 1, 56, 61] the target is: 67\n",
      "eper in ----> t\n",
      "when input is [52, 63, 52, 65, 1, 56, 61, 67] the target is: 62\n",
      "eper int ----> o\n",
      "when input is [62] the target is: 59\n",
      "o ----> l\n",
      "when input is [62, 59] the target is: 51\n",
      "ol ----> d\n",
      "when input is [62, 59, 51] the target is: 1\n",
      "old ---->  \n",
      "when input is [62, 59, 51, 1] the target is: 70\n",
      "old  ----> w\n",
      "when input is [62, 59, 51, 1, 70] the target is: 56\n",
      "old w ----> i\n",
      "when input is [62, 59, 51, 1, 70, 56] the target is: 73\n",
      "old wi ----> z\n",
      "when input is [62, 59, 51, 1, 70, 56, 73] the target is: 48\n",
      "old wiz ----> a\n",
      "when input is [62, 59, 51, 1, 70, 56, 73, 48] the target is: 65\n",
      "old wiza ----> r\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 4 #how many independent sequences will we process parallel\n",
    "block_size = 8 #what is the maximum context size for predictions?\n",
    "def get_batch(split):\n",
    "    #generate a small batch of data\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target is: {target}\")\n",
    "        print(f\"{decode(context.tolist())} ----> {decode([target.item()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595529bd-7694-4c14-84a7-53b2bd7bae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[60, 60, 52, 51, 56, 48, 67, 52],\n",
      "        [ 8,  1, 67, 55, 48, 61, 58,  1],\n",
      "        [52, 63, 52, 65,  1, 56, 61, 67],\n",
      "        [62, 59, 51,  1, 70, 56, 73, 48]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd659a8d-18be-454e-af40-d313deed62e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 74])\n",
      "tensor(4.9733, grad_fn=<NllLossBackward0>)\n",
      "tensor([[0]])\n",
      "tensor([ 0, 61, 53, 10, 22, 67,  5, 63, 20, 30, 31, 36, 28, 45,  8, 70, 56, 11,\n",
      "        15, 35, 14, 59, 41, 27, 17, 64, 25, 65, 17,  1, 14,  4,  0, 24, 57, 68,\n",
      "         1, 65, 69, 12, 39, 33, 54, 50, 49, 23, 53, 10, 19, 34, 17, 54, 61, 30,\n",
      "        45, 20, 69, 73, 23, 29, 43, 43, 20, 52, 45, 71, 71, 22,  9, 23, 13, 27,\n",
      "        46, 19, 71, 28, 57, 46, 24,  4,  6, 62, 16, 30,  4, 31, 23, 40, 45, 22,\n",
      "         9,  6, 32, 31, 54, 73,  4, 70, 47, 39, 42])\n",
      "\n",
      "nf0At'p:IJOGX,wi15N4lTF7qDr7 4&\n",
      "Cju rv2RLgcbBf09M7gnIX:vzBHVV:eXxxA.B3FY9xGjYC&(o6I&JBSXA.(KJgz&wZRU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(42) #hitchhiker's guide to galaxy\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        #each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    def forward(self, idx, targets=None):\n",
    "        #idx and targets are (Batch, Time) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(Batch,Time,Channel)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets) \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            #focus only the last time step\n",
    "            logits = logits[:, -1, :] #becomes (B, C)\n",
    "            #apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1) # (B, C)\n",
    "            #sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(B, 1)\n",
    "            #append sampled index to the runnning sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(idx)\n",
    "idx = m.generate(idx = idx, max_new_tokens=100)\n",
    "print(idx[0])\n",
    "print(decode(idx[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d30b48c-a5c4-4b5f-a9b6-5cb4ad19e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pytorch optimizer\n",
    "#similar to stochastic grad, but more powerful, good fit for small models\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr =1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9405a42-866e-47cb-bbd1-aaa33bcf8162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.303614616394043\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    #evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d931101b-5afe-444d-a897-c96551267ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]])\n",
      "tensor([ 0,  3,  1, 29, 48, 51, 52,  1, 67, 65, 52,  1, 59, 51,  1, 67, 66,  1,\n",
      "        67,  1, 52,  1, 50, 62, 68, 60, 48, 65, 52, 58, 52, 61, 54,  1, 55, 67,\n",
      "         1, 21,  1, 44, 55,  1, 49, 48,  1, 66,  1, 68, 65, 58, 52, 51, 51,  1,\n",
      "        68, 65,  1, 30, 67, 55, 56, 67, 55, 56, 67, 68, 51,  1, 67, 55, 62, 48,\n",
      "        51, 59, 52,  1, 58,  1, 48, 65, 72,  1, 21,  0, 34, 50, 55,  1, 60,  1,\n",
      "         2,  1, 41, 55, 67,  1,  8,  1, 53, 10, 27, 65, 66, 48, 66,  1, 55, 48,\n",
      "        54, 65, 66, 67, 68, 67, 56, 61, 54, 56, 69, 56, 67,  1, 39, 62, 53, 52,\n",
      "        51, 58,  1, 68, 66, 66, 67, 55, 56, 61,  1, 48, 66,  1, 29, 52, 51, 62,\n",
      "        68, 66, 63, 59, 52,  1, 67, 70, 52, 51,  1, 70, 48, 56, 49, 48, 65, 70,\n",
      "        52,  1, 62,  1, 48, 65,  1, 25, 48,  1, 49, 52, 51,  1,  8,  1, 48, 65,\n",
      "        46, 62, 70, 59, 51, 56, 61,  1, 49, 67, 62, 62, 61, 51,  1, 67, 65, 52,\n",
      "         1, 50, 58,  1, 49, 59, 52,  1, 51, 52, 51,  1, 55, 56, 51,  1,  9,  0,\n",
      "         3,  1, 69, 48, 65, 52, 70, 56, 60, 56, 51,  1, 48, 67,  1,  8,  1, 48,\n",
      "        51,  1, 30, 67, 55, 52,  1, 20, 16, 61, 50, 55, 52, 65, 65,  1, 53, 52,\n",
      "         1, 62, 53,  1, 67,  1, 56, 69, 52,  1, 67, 55, 56, 61, 54, 55, 52, 56,\n",
      "        66, 67, 55,  1,  9,  0, 29, 48, 56, 61, 52,  1, 72,  1, 54,  1, 55, 52,\n",
      "        52, 61, 56, 50, 65, 56, 61, 51,  1, 65, 52, 51, 52, 48, 65, 52,  1, 67,\n",
      "        55, 52, 65, 67, 48, 61, 54, 55,  1,  8,  1, 64, 68, 67,  1, 49, 52, 52,\n",
      "         1,  8,  1, 30,  1, 53,  1, 70, 55, 62, 67, 55, 56, 16, 13, 43, 72, 56,\n",
      "        51,  1, 48,  3,  1, 50, 58,  5, 66,  1, 66, 62, 61,  1,  8,  1,  9,  0,\n",
      "        36, 41, 55,  1,  3,  1, 48, 66,  1, 66, 56, 54,  1,  8,  1, 55, 52,  1,\n",
      "        66, 67, 55, 67, 55, 62, 61,  1, 61, 62,  1, 30, 67, 62, 68, 65, 62, 59,\n",
      "        62, 68, 52, 65,  1])\n",
      "\n",
      "\" Hade tre ld ts t e coumarekeng ht ? Wh ba s urkedd ur Ithithitud thoadle k ary ?\n",
      "Mch m ! Tht , f0Frsas hagrstutingivit Rofedk ussthin as Hedousple twed waibarwe o ar Da bed , arYowldin btoond tre ck ble ded hid .\n",
      "\" varewimid at , ad Ithe :6ncherr fe of t ive thingheisth .\n",
      "Haine y g heenicrind redeare thertangh , qut bee , I f whothi63Vyid a\" ck's son , .\n",
      "OTh \" as sig , he sththon no Itourolouer \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(idx)\n",
    "idx = m.generate(idx = idx, max_new_tokens=400)\n",
    "print(idx[0])\n",
    "print(decode(idx[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18a5ffb3-16d5-40e8-ade0-ee3879298db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it's better but we need the tokens to star talking each other we only infering based on the last \n",
    "#SNe ad hede . he wanglevecre , ve heslul -> s\n",
    "#to next characters so that's where transform enter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ccb4a9-13f1-47d4-bacc-8a27085be114",
   "metadata": {},
   "source": [
    "The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9eb224e-34d2-4178-8155-bd13763b3c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#consider the following toy example_:\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 #batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaffb219-564d-431f-9a2c-727b6b1b486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#goal is that tokens communicate with the past that's why we take the mean of everything\n",
    "# before the token we are working in the\n",
    "#e.g. [1,2,3,4,5,6, ...]\n",
    "#we are at token 5 we only comunicate with [1,2,3,4] taking the mean value\n",
    "xback_of_words = torch.zeros((B,T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] #(t,C)\n",
    "        xback_of_words[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5efe507d-c783-44c8-95cb-6aa0a6356d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xback_of_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05c2a083-925b-4da1-a4bb-bb1a3ffae683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97b4ed78-21ce-4eb8-8adc-2d52a237b5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "c=\n",
      "tensor([[5.0000, 7.0000],\n",
      "        [3.5000, 3.5000],\n",
      "        [4.0000, 3.3333]])\n"
     ]
    }
   ],
   "source": [
    "#more efficient\n",
    "torch.manual_seed(1337)\n",
    "a = torch.tril(torch.ones(3,3))  #torch.ones(3,3)\n",
    "a = a / torch.sum(a,1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('b=')\n",
    "print(b)\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d483be6-9c63-45ed-93a8-03ff1eb57288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#consider the following toy example_:\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 #batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "print(x.shape)\n",
    "xback_of_words = torch.zeros((B,T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] #(t,C)\n",
    "        xback_of_words[b, t] = torch.mean(xprev, 0)\n",
    "        \n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x #(B,T,T)@ (B,T,C) ---> (B,T,C)\n",
    "torch.allclose(xback_of_words.float(), xbow2.float(), atol=1e-7, rtol=1e-5)\n",
    "#diagnose(xback_of_words, xbow2)\n",
    "#for i in range(8):\n",
    "#    eq = torch.allclose(xback_of_words[1][i], xbow2[1][i])\n",
    "#    print(eq)\n",
    "#    if not eq:\n",
    "#        print(xback_of_words[1][i])\n",
    "#        print(xbow2[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57174030-261f-4f27-8264-0b419dfee530",
   "metadata": {},
   "source": [
    "## 1. It represents cumulative sums (discrete integration)\n",
    "\n",
    "If you multiply it by a vector  \n",
    "\n",
    "\\[\n",
    "x = (x_1, x_2, x_3)^T\n",
    "\\]\n",
    "\n",
    "then:\n",
    "\n",
    "\\[\n",
    "Lx =\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_1 + x_2 \\\\\n",
    "x_1 + x_2 + x_3\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "So **\\(L\\)** performs a **prefix sum**.\n",
    "\n",
    "This is the discrete analogue of:\n",
    "\n",
    "- integration  \n",
    "- accumulation  \n",
    "- state evolution over time  \n",
    "\n",
    "Thatâ€™s why it appears in:\n",
    "\n",
    "- difference equations  \n",
    "- time-series models  \n",
    "- numerical methods  \n",
    "- signal processing  \n",
    "\n",
    "In your broader interests (**control, dynamics, ML**), this operator is fundamental.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fcf8663-7114-4c93-b0c8-26828f2e9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose(a, b, name_a=\"a\", name_b=\"b\"):\n",
    "    print(\"shape:\", a.shape, b.shape)\n",
    "    print(\"dtype:\", a.dtype, b.dtype)\n",
    "    print(\"device:\", a.device, b.device)\n",
    "    print(\"requires_grad:\", a.requires_grad, b.requires_grad)\n",
    "\n",
    "    # Handle NaNs/Infs explicitly\n",
    "    print(\"has_nan:\", torch.isnan(a).any().item(), torch.isnan(b).any().item())\n",
    "    print(\"has_inf:\", torch.isinf(a).any().item(), torch.isinf(b).any().item())\n",
    "\n",
    "    # Compare\n",
    "    diff = (a - b).abs()\n",
    "    print(\"max_abs_diff:\", diff.max().item())\n",
    "    print(\"allclose default:\", torch.allclose(a, b))\n",
    "    print(\"allclose strict (atol=0, rtol=0):\", torch.allclose(a, b, atol=0.0, rtol=0.0))\n",
    "\n",
    "    # Show where it fails\n",
    "    close_mask = torch.isclose(a, b)\n",
    "    if close_mask.numel() > 0:\n",
    "        bad = (~close_mask).nonzero(as_tuple=False)\n",
    "        if bad.numel() > 0:\n",
    "            i = bad[0].tolist()\n",
    "            print(\"first mismatch index:\", i)\n",
    "            print(f\"{name_a}[i] =\", a[tuple(i)].item())\n",
    "            print(f\"{name_b}[i] =\", b[tuple(i)].item())\n",
    "            print(\"abs diff at i:\", (a[tuple(i)] - b[tuple(i)]).abs().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1a75c13-d178-4998-94c9-707c5e68dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd version\n",
    "tril = torch.tril(torch.ones(T,T)) # using to accumalitive how much each token knows from each other\n",
    "wei = torch.zeros((T,T)) #\"standard\" way to initializes values, all from 'zeros' mean nothing to accumalate, all have the same knowledge at the beggining\n",
    "#remember these are your weights\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) #since we are using a triangular lower form, tokens in the future cannot communicate\n",
    "#all values that are as '-inf', are values from the future\n",
    "wei = F.softmax(wei, dim=-1)#normalize the values\n",
    "xbow3 = wei @ x #give us the current knowledge on x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adda31e-f3fc-4b42-81fb-3a8d99a8f1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nanogpt)",
   "language": "python",
   "name": "nanogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
